package services

import (
	"context"
	"encoding/csv"
	"encoding/json"
	"fmt"
	"math"
	"os"
	"os/exec"
	"path/filepath"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/google/uuid"
	"github.com/yourusername/flex-api/internal/models"
)

type JobService struct {
	storageDir string
	mu         sync.RWMutex
	pythonBin  string
}

func NewJobService(storageDir, pythonBin string) *JobService {
	if pythonBin == "" {
		pythonBin = "python3"
	}
	return &JobService{
		storageDir: storageDir,
		pythonBin:  pythonBin,
	}
}

// â˜… heatmap ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç”¨ï¼šstorageDir ã‚’å…¬é–‹
func (s *JobService) StorageDir() string {
	return s.storageDir
}

// CreateJob ã¯æ–°ã—ã„ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ
func (s *JobService) CreateJob(params models.AnalysisParams) (*models.JobResponse, error) {
	// ãƒ‡ãƒãƒƒã‚°: å—ã‘å–ã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
	fmt.Printf("[DEBUG] CreateJob - Received params:\n")
	fmt.Printf("  UniProtIDs: %s\n", params.UniProtIDs)
	if params.Method != nil {
		fmt.Printf("  Method: %s (pointer)\n", *params.Method)
	} else {
		fmt.Printf("  Method: nil\n")
	}
	if params.SeqRatio != nil {
		fmt.Printf("  SeqRatio: %f (pointer)\n", *params.SeqRatio)
	} else {
		fmt.Printf("  SeqRatio: nil\n")
	}
	if params.NegativePDBID != nil {
		fmt.Printf("  NegativePDBID: %s (pointer)\n", *params.NegativePDBID)
	} else {
		fmt.Printf("  NegativePDBID: nil\n")
	}
	if params.CisThreshold != nil {
		fmt.Printf("  CisThreshold: %f (pointer)\n", *params.CisThreshold)
	} else {
		fmt.Printf("  CisThreshold: nil\n")
	}
	if params.Export != nil {
		fmt.Printf("  Export: %t (pointer)\n", *params.Export)
	} else {
		fmt.Printf("  Export: nil\n")
	}
	if params.Heatmap != nil {
		fmt.Printf("  Heatmap: %t (pointer)\n", *params.Heatmap)
	} else {
		fmt.Printf("  Heatmap: nil\n")
	}
	if params.ProcCis != nil {
		fmt.Printf("  ProcCis: %t (pointer)\n", *params.ProcCis)
	} else {
		fmt.Printf("  ProcCis: nil\n")
	}
	if params.Overwrite != nil {
		fmt.Printf("  Overwrite: %t (pointer)\n", *params.Overwrite)
	} else {
		fmt.Printf("  Overwrite: nil\n")
	}

	// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
	if params.Method == nil || *params.Method == "" {
		defaultMethod := "X-ray"
		params.Method = &defaultMethod
		fmt.Printf("[DEBUG] CreateJob - Set default Method: %s\n", defaultMethod)
	}
	if params.SeqRatio == nil || *params.SeqRatio <= 0 || *params.SeqRatio > 1 {
		defaultSeqRatio := 0.2
		params.SeqRatio = &defaultSeqRatio
		fmt.Printf("[DEBUG] CreateJob - Set default SeqRatio: %f\n", defaultSeqRatio)
	}
	if params.CisThreshold == nil || *params.CisThreshold <= 0 {
		defaultCisThreshold := 3.3
		params.CisThreshold = &defaultCisThreshold
		fmt.Printf("[DEBUG] CreateJob - Set default CisThreshold: %f\n", defaultCisThreshold)
	}
	if params.NegativePDBID == nil {
		emptyStr := ""
		params.NegativePDBID = &emptyStr
		fmt.Printf("[DEBUG] CreateJob - Set default NegativePDBID: (empty)\n")
	}
	if params.Export == nil {
		defaultExport := true
		params.Export = &defaultExport
		fmt.Printf("[DEBUG] CreateJob - Set default Export: %t\n", defaultExport)
	}
	if params.Heatmap == nil {
		defaultHeatmap := true
		params.Heatmap = &defaultHeatmap
		fmt.Printf("[DEBUG] CreateJob - Set default Heatmap: %t\n", defaultHeatmap)
	}
	if params.ProcCis == nil {
		defaultProcCis := true
		params.ProcCis = &defaultProcCis
		fmt.Printf("[DEBUG] CreateJob - Set default ProcCis: %t\n", defaultProcCis)
	}
	if params.Overwrite == nil {
		defaultOverwrite := true
		params.Overwrite = &defaultOverwrite
		fmt.Printf("[DEBUG] CreateJob - Set default Overwrite: %t\n", defaultOverwrite)
	}

	// ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
	jobID := uuid.New().String()

	// ã‚¸ãƒ§ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
	jobDir := filepath.Join(s.storageDir, jobID)
	if err := os.MkdirAll(jobDir, 0o755); err != nil {
		return nil, fmt.Errorf("failed to create job directory: %w", err)
	}

	// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆæœŸåŒ–
	status := models.JobStatus{
		JobID:     jobID,
		Status:    "pending",
		Progress:  0,
		Message:   "Job created",
		CreatedAt: time.Now(),
		UpdatedAt: time.Now(),
	}

	if err := s.saveJobStatus(jobID, status); err != nil {
		return nil, err
	}

	// éåŒæœŸã§è§£æå®Ÿè¡Œ
	go s.executeDSAAnalysis(jobID, params)

	return &models.JobResponse{
		JobID:     jobID,
		Status:    status.Status,
		CreatedAt: status.CreatedAt,
	}, nil
}

// GetJobStatus ã¯ã‚¸ãƒ§ãƒ–ã®çŠ¶æ…‹ã‚’å–å¾—
func (s *JobService) GetJobStatus(jobID string) (*models.JobStatus, error) {
	statusPath := filepath.Join(s.storageDir, jobID, "status.json")

	data, err := os.ReadFile(statusPath)
	if err != nil {
		if os.IsNotExist(err) {
			return nil, fmt.Errorf("job not found: %s", jobID)
		}
		return nil, fmt.Errorf("failed to read status: %w", err)
	}

	var status models.JobStatus
	if err := json.Unmarshal(data, &status); err != nil {
		return nil, fmt.Errorf("failed to parse status: %w", err)
	}

	return &status, nil
}

// GetResult ã¯ã‚¸ãƒ§ãƒ–ã®çµæœã‚’å–å¾—
func (s *JobService) GetResult(jobID string) (*models.NotebookDSAResult, error) {
	// ãƒ‡ãƒãƒƒã‚°: ã‚¸ãƒ§ãƒ–IDã‚’ãƒ­ã‚°å‡ºåŠ›
	fmt.Printf("[DEBUG] GetResult - JobID: %s\n", jobID)

	// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
	status, err := s.GetJobStatus(jobID)
	if err != nil {
		fmt.Printf("[DEBUG] GetResult - Failed to get job status: %v\n", err)
		return nil, err
	}

	fmt.Printf("[DEBUG] GetResult - Job status: %s\n", status.Status)

	if status.Status != "completed" {
		return nil, fmt.Errorf("job not completed: %s", status.Status)
	}

	// Notebook DSAã¯summary.csvã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã€ã¾ãšsummary.csvã‚’ç¢ºèª
	summaryPath := filepath.Join(s.storageDir, jobID, "summary.csv")
	resultPath := filepath.Join(s.storageDir, jobID, "result.json")

	// result.jsonãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’èª­ã¿è¾¼ã‚€
	if _, err := os.Stat(resultPath); err == nil {
		fmt.Printf("[DEBUG] GetResult - Found result.json at: %s\n", resultPath)
		data, err := os.ReadFile(resultPath)
		if err != nil {
			fmt.Printf("[DEBUG] GetResult - Failed to read result.json: %v\n", err)
			return nil, fmt.Errorf("failed to read result: %w", err)
		}

		var result models.NotebookDSAResult
		if err := json.Unmarshal(data, &result); err != nil {
			fmt.Printf("[DEBUG] GetResult - Failed to parse result.json: %v\n", err)
			return nil, fmt.Errorf("failed to parse result: %w", err)
		}

		fmt.Printf("[DEBUG] GetResult - Successfully loaded result.json\n")
		return &result, nil
	}

	// result.jsonãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€summary.csvã‹ã‚‰çµæœã‚’æ§‹ç¯‰
	if _, err := os.Stat(summaryPath); err == nil {
		fmt.Printf("[DEBUG] GetResult - Found summary.csv at: %s (converting to NotebookDSAResult)\n", summaryPath)
		return s.convertSummaryCSVToResult(jobID, summaryPath)
	}

	// ã©ã¡ã‚‰ã‚‚å­˜åœ¨ã—ãªã„å ´åˆ
	fmt.Printf("[DEBUG] GetResult - Neither result.json nor summary.csv found\n")
	return nil, fmt.Errorf("result file not found. Checked: %s and %s", resultPath, summaryPath)
}

// convertSummaryCSVToResult ã¯summary.csvã‹ã‚‰NotebookDSAResultã‚’æ§‹ç¯‰
func (s *JobService) convertSummaryCSVToResult(jobID string, summaryPath string) (*models.NotebookDSAResult, error) {
	fmt.Printf("[DEBUG] convertSummaryCSVToResult - Reading summary.csv from: %s\n", summaryPath)

	// summary.csvã‚’èª­ã¿è¾¼ã‚€
	file, err := os.Open(summaryPath)
	if err != nil {
		return nil, fmt.Errorf("failed to open summary.csv: %w", err)
	}
	defer file.Close()

	reader := csv.NewReader(file)
	records, err := reader.ReadAll()
	if err != nil {
		return nil, fmt.Errorf("failed to read summary.csv: %w", err)
	}

	if len(records) < 2 {
		return nil, fmt.Errorf("summary.csv has insufficient rows: %d", len(records))
	}

	// ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å–å¾—
	headers := records[0]
	data := records[1]

	// ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
	headerMap := make(map[string]int)
	for i, h := range headers {
		headerMap[strings.TrimSpace(h)] = i
	}

	// ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
	getString := func(key string) string {
		if idx, ok := headerMap[key]; ok && idx < len(data) {
			return strings.TrimSpace(data[idx])
		}
		return ""
	}

	getInt := func(key string) int {
		val := getString(key)
		if val == "" {
			return 0
		}
		if i, err := strconv.Atoi(val); err == nil {
			return i
		}
		return 0
	}

	getFloat := func(key string) float64 {
		val := getString(key)
		if val == "" {
			return 0.0
		}
		if f, err := strconv.ParseFloat(val, 64); err == nil {
			return f
		}
		return 0.0
	}

	uniprotID := getString("uniprotid")
	seqRatio := getFloat("seq_ratio")
	entries := getInt("Entries")
	chains := getInt("Chains")
	length := getInt("Length")
	lengthPercent := getFloat("Length(%)")
	resolution := getFloat("Resolution")
	umf := getFloat("UMF")
	meanCisDist := getFloat("mean_cisDist")
	stdCisDist := getFloat("std_cisDist")
	meanCisScore := getFloat("mean_cisScore")
	cisNum := getInt("cis")
	mix := getInt("mix")

	fmt.Printf("[DEBUG] convertSummaryCSVToResult - Parsed data: uniprotID=%s, entries=%d, chains=%d, length=%d\n", 
		uniprotID, entries, chains, length)

	// è·é›¢ãƒ‡ãƒ¼ã‚¿ã¨cisãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§PairScoreã‚’æ§‹ç¯‰
	jobDir := filepath.Dir(summaryPath)
	distancePath := filepath.Join(jobDir, fmt.Sprintf("distance_%s.csv", uniprotID))
	
	// cisãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³: {uniprotID}_{seqRatio}_cis_nor+sub.csvï¼‰
	// seqRatioã¯0.2ã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«åã¯ "C6H0Y9_0.2_cis_nor+sub.csv" ã®ã‚ˆã†ã«ãªã‚‹
	cisPath := ""
	cisPattern := fmt.Sprintf("%s_%.1f_cis_nor+sub.csv", uniprotID, seqRatio)
	cisPath = filepath.Join(jobDir, cisPattern)
	
	// ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã§æ¤œç´¢
	if _, err := os.Stat(cisPath); err != nil {
		// ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
		if entries, err := os.ReadDir(jobDir); err == nil {
			for _, entry := range entries {
				if !entry.IsDir() && strings.Contains(entry.Name(), uniprotID) && 
				   strings.Contains(entry.Name(), "_cis_") && strings.HasSuffix(entry.Name(), ".csv") {
					cisPath = filepath.Join(jobDir, entry.Name())
					fmt.Printf("[DEBUG] convertSummaryCSVToResult - Found cis file: %s\n", cisPath)
					break
				}
			}
		}
	}
	
	trimsequencePath := filepath.Join(jobDir, fmt.Sprintf("trimsequence_%s.csv", uniprotID))

	// PairScoreã‚’æ§‹ç¯‰ï¼ˆcisãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
	var pairScores []models.PairScore
	var cisPairs []string

	if _, err := os.Stat(cisPath); err == nil {
		fmt.Printf("[DEBUG] convertSummaryCSVToResult - Reading cis data from: %s\n", cisPath)
		cisFile, err := os.Open(cisPath)
		if err == nil {
			defer cisFile.Close()
			cisReader := csv.NewReader(cisFile)
			cisRecords, err := cisReader.ReadAll()
			if err == nil && len(cisRecords) > 1 {
				// ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
				for i := 1; i < len(cisRecords); i++ {
					row := cisRecords[i]
					if len(row) < 3 {
						continue
					}

					// æœ€åˆã®åˆ—ã‹ã‚‰æ®‹åŸºãƒšã‚¢ã‚’å–å¾—ï¼ˆ"1, 2"å½¢å¼ï¼‰
					pairStr := strings.Trim(row[0], `"`)
					parts := strings.Split(pairStr, ", ")
					if len(parts) != 2 {
						continue
					}

					iIdx, err1 := strconv.Atoi(parts[0])
					jIdx, err2 := strconv.Atoi(parts[1])
					if err1 != nil || err2 != nil {
						continue
					}

					// æ®‹åŸºãƒšã‚¢åã‚’å–å¾—
					residuePair := ""
					if len(row) > 1 {
						residuePair = strings.Trim(row[1], `"`)
					}

					// distance mean, distance std, scoreã‚’å–å¾—
					var distanceMean, distanceStd, score float64
					if len(row) > 15 {
						if f, err := strconv.ParseFloat(row[15], 64); err == nil {
							distanceMean = f
						}
					}
					if len(row) > 16 {
						if f, err := strconv.ParseFloat(row[16], 64); err == nil {
							distanceStd = f
						}
					}
					if len(row) > 17 {
						if f, err := strconv.ParseFloat(row[17], 64); err == nil {
							score = f
						}
					}

					// cis_cntã‚’ç¢ºèªï¼ˆå…¨æ§‹é€ ã§cisã®å ´åˆã¯cisPairsã«è¿½åŠ ï¼‰
					cisCnt := 0
					if len(row) > 18 {
						if i, err := strconv.Atoi(row[18]); err == nil {
							cisCnt = i
						}
					}
					transCnt := 0
					if len(row) > 19 {
						if i, err := strconv.Atoi(row[19]); err == nil {
							transCnt = i
						}
					}

					// å…¨æ§‹é€ ã§cisã®å ´åˆï¼ˆtrans_cnt == 0ï¼‰
					if transCnt == 0 && cisCnt > 0 {
						cisPairs = append(cisPairs, pairStr)
					}

					pairScores = append(pairScores, models.PairScore{
						I:            iIdx,
						J:            jIdx,
						ResiduePair:  residuePair,
						DistanceMean: distanceMean,
						DistanceStd:  distanceStd,
						Score:        score,
					})
				}
			}
		}
	}

	// è·é›¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚‚PairScoreã‚’æ§‹ç¯‰ï¼ˆcisãƒ‡ãƒ¼ã‚¿ã«ãªã„ãƒšã‚¢ã‚‚å«ã‚ã‚‹ï¼‰
	if _, err := os.Stat(distancePath); err == nil {
		fmt.Printf("[DEBUG] convertSummaryCSVToResult - Reading distance data from: %s\n", distancePath)
		// è·é›¢ãƒ‡ãƒ¼ã‚¿ã¯headerãªã—ãªã®ã§ã€æ‰‹å‹•ã§ãƒ‘ãƒ¼ã‚¹
		// ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: residue_num1,residue_num2,distance1,distance2,...
		distanceFile, err := os.Open(distancePath)
		if err == nil {
			defer distanceFile.Close()
			distanceReader := csv.NewReader(distanceFile)
			distanceRecords, err := distanceReader.ReadAll()
			if err == nil {
				// æ—¢å­˜ã®pairScoresã®ãƒãƒƒãƒ—ã‚’ä½œæˆï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
				pairMap := make(map[string]bool)
				for _, ps := range pairScores {
					key := fmt.Sprintf("%d,%d", ps.I, ps.J)
					pairMap[key] = true
				}

				// è·é›¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¹³å‡ã¨æ¨™æº–åå·®ã‚’è¨ˆç®—
				for _, row := range distanceRecords {
					if len(row) < 2 {
						continue
					}

					iIdx, err1 := strconv.Atoi(row[0])
					jIdx, err2 := strconv.Atoi(row[1])
					if err1 != nil || err2 != nil {
						continue
					}

					key := fmt.Sprintf("%d,%d", iIdx, jIdx)
					if pairMap[key] {
						continue // æ—¢ã«cisãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¿½åŠ æ¸ˆã¿
					}

					// è·é›¢å€¤ã‚’å–å¾—ï¼ˆ3åˆ—ç›®ä»¥é™ï¼‰
					var distances []float64
					for i := 2; i < len(row); i++ {
						if f, err := strconv.ParseFloat(row[i], 64); err == nil {
							distances = append(distances, f)
						}
					}

					if len(distances) == 0 {
						continue
					}

					// å¹³å‡ã¨æ¨™æº–åå·®ã‚’è¨ˆç®—
					var sum float64
					for _, d := range distances {
						sum += d
					}
					mean := sum / float64(len(distances))

					var variance float64
					for _, d := range distances {
						variance += (d - mean) * (d - mean)
					}
					std := math.Sqrt(variance / float64(len(distances)))

					// scoreã‚’è¨ˆç®—ï¼ˆmean / stdã€stdãŒ0ã®å ´åˆã¯0.0001ï¼‰
					score := mean / std
					if std == 0 {
						score = mean / 0.0001
					}

					// æ®‹åŸºãƒšã‚¢åã‚’å–å¾—ï¼ˆtrimsequenceã‹ã‚‰æ¨æ¸¬ã™ã‚‹ã‹ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
					residuePair := fmt.Sprintf("RES-%d, RES-%d", iIdx, jIdx)

					pairScores = append(pairScores, models.PairScore{
						I:            iIdx,
						J:            jIdx,
						ResiduePair:  residuePair,
						DistanceMean: mean,
						DistanceStd:  std,
						Score:        score,
					})
				}
			}
		}
	}

	// PerResidueScoreã‚’æ§‹ç¯‰ï¼ˆtrimsequenceã‹ã‚‰ï¼‰
	var perResidueScores []models.PerResidueScore
	if _, err := os.Stat(trimsequencePath); err == nil {
		fmt.Printf("[DEBUG] convertSummaryCSVToResult - Reading trimsequence from: %s\n", trimsequencePath)
		trimFile, err := os.Open(trimsequencePath)
		if err == nil {
			defer trimFile.Close()
			trimReader := csv.NewReader(trimFile)
			trimRecords, err := trimReader.ReadAll()
			if err == nil && len(trimRecords) > 0 {
				// æœ€åˆã®åˆ—ãŒUniProté…åˆ—
				for idx, row := range trimRecords {
					if len(row) == 0 {
						continue
					}
					residueName := strings.TrimSpace(row[0])
					// 3æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‹ã‚‰1æ–‡å­—ã‚³ãƒ¼ãƒ‰ã«å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰
					residueName1 := residueName
					if len(residueName) == 3 {
						// ç°¡æ˜“å¤‰æ›ï¼ˆå®Œå…¨ãªå¤‰æ›ãƒ†ãƒ¼ãƒ–ãƒ«ã¯å®Ÿè£…ã—ãªã„ï¼‰
						residueName1 = residueName
					}

					// ã“ã®æ®‹åŸºã«é–¢é€£ã™ã‚‹ãƒšã‚¢ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
					var scores []float64
					for _, ps := range pairScores {
						if ps.I == idx+1 || ps.J == idx+1 {
							if !math.IsNaN(ps.Score) && !math.IsInf(ps.Score, 0) {
								scores = append(scores, ps.Score)
							}
						}
					}

					avgScore := 0.0
					if len(scores) > 0 {
						var sum float64
						for _, s := range scores {
							sum += s
						}
						avgScore = sum / float64(len(scores))
					}

					perResidueScores = append(perResidueScores, models.PerResidueScore{
						Index:         idx,
						ResidueNumber: idx + 1,
						ResidueName:   residueName1,
						Score:         avgScore,
					})
				}
			}
		}
	}

	// PDB IDãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆdistanceãƒ‡ãƒ¼ã‚¿ã®åˆ—åã‹ã‚‰ã€ã¾ãŸã¯atom_coordãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ï¼‰
	var pdbIDs []string
	atomCoordDir := filepath.Join(jobDir, "atom_coord")
	if entries, err := os.ReadDir(atomCoordDir); err == nil {
		for _, entry := range entries {
			if !entry.IsDir() && strings.HasSuffix(entry.Name(), ".csv") {
				pdbID := strings.TrimSuffix(entry.Name(), ".csv")
				pdbIDs = append(pdbIDs, strings.ToUpper(pdbID))
			}
		}
	}
	if len(pdbIDs) == 0 {
		// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
		pdbIDs = []string{}
	}

	// ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ§‹ç¯‰ï¼ˆç°¡æ˜“ç‰ˆï¼špairScoresã‹ã‚‰ï¼‰
	heatmapSize := length
	if heatmapSize == 0 {
		heatmapSize = 100 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
	}
	// NaNã‚’è¡¨ç¾ã™ã‚‹ãŸã‚ã«ã€nilå¯èƒ½ãªfloat64ãƒã‚¤ãƒ³ã‚¿ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ä½¿ç”¨
	heatmapValues := make([][]*float64, heatmapSize)
	for i := range heatmapValues {
		heatmapValues[i] = make([]*float64, heatmapSize)
		// åˆæœŸå€¤ã¯nilï¼ˆJSONã§ã¯nullã¨ã—ã¦è¡¨ç¾ã•ã‚Œã‚‹ï¼‰
	}

	// pairScoresã‹ã‚‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ§‹ç¯‰
	for _, ps := range pairScores {
		i := ps.I - 1 // 0-based
		j := ps.J - 1 // 0-based
		if i >= 0 && i < heatmapSize && j >= 0 && j < heatmapSize {
			if !math.IsNaN(ps.Score) && !math.IsInf(ps.Score, 0) {
				scoreVal := ps.Score
				heatmapValues[i][j] = &scoreVal
			}
			// NaNã¾ãŸã¯Infã®å ´åˆã¯nilã®ã¾ã¾ï¼ˆJSONã§ã¯nullï¼‰
		}
	}

	// çµ±è¨ˆã‚’è¨ˆç®—
	pairScoreMean := 0.0
	pairScoreStd := 0.0
	if len(pairScores) > 0 {
		var scores []float64
		for _, ps := range pairScores {
			if !math.IsNaN(ps.Score) && !math.IsInf(ps.Score, 0) {
				scores = append(scores, ps.Score)
			}
		}
		if len(scores) > 0 {
			var sum float64
			for _, s := range scores {
				sum += s
			}
			pairScoreMean = sum / float64(len(scores))

			var variance float64
			for _, s := range scores {
				variance += (s - pairScoreMean) * (s - pairScoreMean)
			}
			pairScoreStd = math.Sqrt(variance / float64(len(scores)))
		}
	}

	// ãƒ•ãƒ«é…åˆ—é•·ã‚’è¨ˆç®—ï¼ˆlength / lengthPercent * 100ï¼‰
	fullSequenceLength := 0
	if lengthPercent > 0 {
		fullSequenceLength = int(float64(length) / lengthPercent * 100.0)
	}

	// åˆ†è§£èƒ½ã‚’è¨­å®š
	var top5ResolutionMean *float64
	if resolution > 0 {
		top5ResolutionMean = &resolution
	}

	// CisInfoã‚’æ§‹ç¯‰
	cisInfo := models.CisInfo{
		CisDistMean:  meanCisDist,
		CisDistStd:   stdCisDist,
		CisScoreMean: meanCisScore,
		CisNum:       cisNum,
		Mix:          mix,
		CisPairs:     cisPairs,
		Threshold:    3.3, // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆå®Ÿéš›ã®å€¤ã¯å–å¾—ã§ããªã„å ´åˆãŒã‚ã‚‹ï¼‰
	}

	// NotebookDSAResultã‚’æ§‹ç¯‰
	result := &models.NotebookDSAResult{
		UniProtID:            uniprotID,
		NumStructures:        entries,
		NumResidues:          length,
		PDBIDs:               pdbIDs,
		ExcludedPDBs:         []string{},
		SeqRatio:             seqRatio,
		Method:               "X-ray", // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
		FullSequenceLength:   fullSequenceLength,
		ResidueCoveragePercent: lengthPercent,
		NumChains:            chains,
		Top5ResolutionMean:   top5ResolutionMean,
		UMF:                  umf,
		PairScoreMean:        pairScoreMean,
		PairScoreStd:         pairScoreStd,
		PairScores:           pairScores,
		PerResidueScores:     perResidueScores,
		Heatmap: &models.Heatmap{
			Size:   heatmapSize,
			Values: heatmapValues,
		},
		CisInfo: cisInfo,
	}

	fmt.Printf("[DEBUG] convertSummaryCSVToResult - Successfully converted summary.csv to NotebookDSAResult\n")
	fmt.Printf("[DEBUG] convertSummaryCSVToResult - Result: uniprotID=%s, numStructures=%d, numResidues=%d, pairScores=%d\n",
		result.UniProtID, result.NumStructures, result.NumResidues, len(result.PairScores))

	return result, nil
}

// executeDSAAnalysis ã¯Python CLIã‚’å®Ÿè¡Œï¼ˆéåŒæœŸï¼‰
func (s *JobService) executeDSAAnalysis(jobID string, params models.AnalysisParams) {
	// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°: processing
	s.updateJobStatus(jobID, "processing", 0, "Starting analysis...")

	// å‡ºåŠ›ãƒ‘ã‚¹ï¼ˆçµæœ JSON ã¨ heatmap.png ã¯åŒã˜ job ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç½®ãå‰æï¼‰
	jobDir := filepath.Join(s.storageDir, jobID)
	if err := os.MkdirAll(jobDir, 0o755); err != nil {
		s.updateJobStatus(jobID, "failed", 0, fmt.Sprintf("failed to create job dir: %v", err))
		return
	}

	resultPath := filepath.Join(jobDir, "result.json")

	// çµ¶å¯¾ãƒ‘ã‚¹åŒ–ï¼ˆPython å´ã« cwd ä¾å­˜ã—ãªã„ãƒ‘ã‚¹ã‚’æ¸¡ã™ï¼‰
	absResultPath, err := filepath.Abs(resultPath)
	if err != nil {
		s.updateJobStatus(jobID, "failed", 0, fmt.Sprintf("failed to resolve result path: %v", err))
		return
	}

	// ================================
	//  ğŸ”´ ã“ã“ãŒã€ŒPython å®Ÿè¡Œç’°å¢ƒã‚ã‚ã›ã€ã®è‚
	// ================================
	// 1) python ãƒã‚¤ãƒŠãƒªã¯èµ·å‹•æ™‚ãƒ•ãƒ©ã‚° -python ã§ /opt/anaconda3/bin/python ã‚’æ¸¡ã™
	// 2) PYTHON_ENGINE_DIR ç’°å¢ƒå¤‰æ•°ã« python-engine ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã¦ãŠã
	//    ä¾‹: export PYTHON_ENGINE_DIR="/Users/xxx/Desktop/protein-flexibility-platform/python-engine"
	pythonWorkDir := os.Getenv("PYTHON_ENGINE_DIR")
	if pythonWorkDir == "" {
		// ä¸€æ—¦ã‚«ãƒ¬ãƒ³ãƒˆã®ã¾ã¾ã§ã‚‚å‹•ãã‚ˆã†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
		pythonWorkDir, _ = os.Getwd()
	}

	// Notebook DSA CLIã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
	args := []string{
		"-m", "flex_analyzer.cli", "notebook",
		"--uniprot-ids", params.UniProtIDs,
		"--method", *params.Method,
		"--seq-ratio", fmt.Sprintf("%.2f", *params.SeqRatio),
		"--cis-threshold", fmt.Sprintf("%.2f", *params.CisThreshold),
		"--output-dir", filepath.Dir(absResultPath),
		"--pdb-dir", filepath.Join(filepath.Dir(absResultPath), "pdb_files"),
	}
	
	// negative_pdbidãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¿½åŠ 
	if params.NegativePDBID != nil && *params.NegativePDBID != "" {
		args = append(args, "--negative-pdbid", *params.NegativePDBID)
	}
	
	// ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ãƒ©ã‚°
	if *params.Export {
		args = append(args, "--export")
	} else {
		args = append(args, "--no-export")
	}
	if *params.Heatmap {
		args = append(args, "--heatmap")
	} else {
		args = append(args, "--no-heatmap")
	}
	if *params.ProcCis {
		args = append(args, "--proc-cis")
	} else {
		args = append(args, "--no-proc-cis")
	}
	if *params.Overwrite {
		args = append(args, "--overwrite")
	} else {
		args = append(args, "--no-overwrite")
	}
	args = append(args, "--verbose")

	// ãƒ‡ãƒãƒƒã‚°: å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ã‚’ãƒ­ã‚°å‡ºåŠ›
	fmt.Printf("[DEBUG] executeDSAAnalysis - Command: %s %v\n", s.pythonBin, args)
	fmt.Printf("[DEBUG] executeDSAAnalysis - Working directory: %s\n", "/Users/kondoubyakko/Desktop/protein-flexibility-platform/python-engine")

	// ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ30åˆ† = 1800ç§’ï¼‰
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()
	
	cmd := exec.CommandContext(ctx, s.pythonBin, args...)
	cmd.Dir = "/Users/kondoubyakko/Desktop/protein-flexibility-platform/python-engine"
	env := os.Environ()
	env = append(env, "PYTHONPATH=./src")
	cmd.Env = env

	// æ¨™æº–å‡ºåŠ›/ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
	fmt.Printf("[DEBUG] executeDSAAnalysis - Starting Python command execution...\n")
	output, err := cmd.CombinedOutput()

	// ãƒ‡ãƒãƒƒã‚°: å‡ºåŠ›ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®1000æ–‡å­—ã®ã¿ï¼‰
	outputStr := string(output)
	if len(outputStr) > 1000 {
		fmt.Printf("[DEBUG] executeDSAAnalysis - Output (first 1000 chars): %s\n", outputStr[:1000])
		fmt.Printf("[DEBUG] executeDSAAnalysis - Output length: %d\n", len(outputStr))
	} else {
		fmt.Printf("[DEBUG] executeDSAAnalysis - Full output: %s\n", outputStr)
	}

	if err != nil {
		var errorMsg string
		// ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
		if ctx.Err() == context.DeadlineExceeded {
			errorMsg = "Python CLI execution timed out after 30 minutes"
			fmt.Printf("[DEBUG] executeDSAAnalysis - Timeout error: %v\n", err)
			s.updateJobStatus(jobID, "failed", 0, errorMsg)
		} else {
			// ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
			outputPreview := outputStr
			if len(outputStr) > 2000 {
				outputPreview = outputStr[len(outputStr)-2000:]
			}
			errorMsg = fmt.Sprintf("Python CLI failed: %v\nOutput (last 2000 chars): %s", err, outputPreview)
			fmt.Printf("[DEBUG] executeDSAAnalysis - Execution error: %v\n", err)
			s.updateJobStatus(jobID, "failed", 0, errorMsg)
		}

		// ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
		errorData := models.ErrorResponse{
			Error: errorMsg,
			PartialResult: map[string]interface{}{
				"output": outputStr,
			},
		}
		errorJSON, _ := json.MarshalIndent(errorData, "", "  ")
		_ = os.WriteFile(filepath.Join(jobDir, "error.json"), errorJSON, 0o644)

		return
	}

	fmt.Printf("[DEBUG] executeDSAAnalysis - Python command completed successfully\n")

	// Notebook DSAã¯summary.csvã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã€result.jsonãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹
	// summary.csvã‹ã‚‰çµæœã‚’èª­ã¿è¾¼ã‚“ã§result.jsonã«å¤‰æ›ã™ã‚‹ã‹ã€summary.csvã®å­˜åœ¨ã‚’ç¢ºèª
	summaryPath := filepath.Join(filepath.Dir(absResultPath), "summary.csv")
	if _, err := os.Stat(summaryPath); err == nil {
		fmt.Printf("[DEBUG] executeDSAAnalysis - Found summary.csv at: %s\n", summaryPath)
		// summary.csvãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã€ãã‚Œã‚’result.jsonã¨ã—ã¦ä¿å­˜ã™ã‚‹ã‹ã€
		// ã¾ãŸã¯GetResulté–¢æ•°ã§summary.csvã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
		// ã“ã“ã§ã¯ã€summary.csvã®å­˜åœ¨ã‚’ç¢ºèªã—ã¦ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã ã‘
	}

	// å®Œäº†
	s.updateJobStatus(jobID, "completed", 100, "Analysis completed")
}

// updateJobStatus ã¯ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
func (s *JobService) updateJobStatus(jobID, status string, progress int, message string) {
	s.mu.Lock()
	defer s.mu.Unlock()

	jobStatus := models.JobStatus{
		JobID:     jobID,
		Status:    status,
		Progress:  progress,
		Message:   message,
		UpdatedAt: time.Now(),
	}

	// æ—¢å­˜ã®CreatedAtã‚’ä¿æŒ
	existingStatus, err := s.GetJobStatus(jobID)
	if err == nil {
		jobStatus.CreatedAt = existingStatus.CreatedAt
	} else {
		jobStatus.CreatedAt = time.Now()
	}

	_ = s.saveJobStatus(jobID, jobStatus)
}

// saveJobStatus ã¯ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
func (s *JobService) saveJobStatus(jobID string, status models.JobStatus) error {
	statusPath := filepath.Join(s.storageDir, jobID, "status.json")

	data, err := json.MarshalIndent(status, "", "  ")
	if err != nil {
		return fmt.Errorf("failed to marshal status: %w", err)
	}

	if err := os.WriteFile(statusPath, data, 0o644); err != nil {
		return fmt.Errorf("failed to write status: %w", err)
	}

	return nil
}
