from __future__ import annotations

from pathlib import Path
from typing import List, Optional, Set, Tuple

import numpy as np
import requests
from requests.exceptions import HTTPError

from src.flex_analyzer.parser import extract_ca_coords_from_files
from src.flex_analyzer.models import ResidueData, StructureSet


# UniProt ã‚¨ãƒ³ãƒˆãƒª JSON ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
UNIPROT_ENTRY_API = "https://rest.uniprot.org/uniprotkb/{uniprot_id}?format=json"

# PDB ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL
RCSB_PDB_DOWNLOAD = "https://files.rcsb.org/download/{pdb_id}.pdb"


# ========= UniProt / PDB å–å¾—ã¾ã‚ã‚Š =========


def _fetch_uniprot_json(uniprot_id: str) -> dict:
    """å˜ä¸€ UniProt ã‚¨ãƒ³ãƒˆãƒªã® JSON ã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ã€‚"""
    url = UNIPROT_ENTRY_API.format(uniprot_id=uniprot_id)
    print(f"[UniProt] ã‚¨ãƒ³ãƒˆãƒªå–å¾—: {url}")
    resp = requests.get(url, timeout=30)
    resp.raise_for_status()
    return resp.json()


def _resolve_active_uniprot_id(uniprot_id: str, _visited: Optional[Set[str]] = None) -> str:
    """
    Inactive (DEMERGED) ãª UniProt ID ã®å ´åˆã€
    inactiveReason.mergeDemergeTo ã‚’è¾¿ã£ã¦ Active ãª ID ã‚’è¿”ã™ã€‚
    """
    if _visited is None:
        _visited = set()
    if uniprot_id in _visited:
        raise RuntimeError(f"UniProt ID ã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆãŒãƒ«ãƒ¼ãƒ—ã—ã¾ã—ãŸ: {uniprot_id}")
    _visited.add(uniprot_id)

    data = _fetch_uniprot_json(uniprot_id)
    entry_type = data.get("entryType")

    if entry_type == "Inactive":
        inactive_reason = data.get("inactiveReason", {}) or {}
        merge_targets = inactive_reason.get("mergeDemergeTo") or []
        if merge_targets:
            new_id = merge_targets[0]
            print(
                f"  âš ï¸ UniProt {uniprot_id} ã¯ Inactive (DEMERGED) ã§ã™ã€‚"
                f" ä»£ã‚ã‚Šã« {new_id} ã‚’ä½¿ã„ã¾ã™ã€‚"
            )
            return _resolve_active_uniprot_id(new_id, _visited=_visited)
        raise RuntimeError(f"UniProt {uniprot_id} ã¯ Inactive ã§ã™ãŒç§»è¡Œå…ˆãŒä¸æ˜ã§ã™ã€‚")

    # Active ãªå ´åˆã¯ãã®ã¾ã¾
    return uniprot_id


def _fetch_pdb_ids_for_active_uniprot(uniprot_id: str) -> List[str]:
    """
    Active ãª UniProt ID ã‹ã‚‰ PDB ID ä¸€è¦§ã‚’å–å¾—ã™ã‚‹ã€‚

    JSON ã®ã©ã“ã« PDB Cross-Ref ãŒå…¥ã£ã¦ã„ã‚‹ã‹ã¯
    ã‚¨ãƒ³ãƒˆãƒªã«ã‚ˆã£ã¦ç•°ãªã‚‹ã®ã§ã€è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã‚‹ã€‚
    """
    data = _fetch_uniprot_json(uniprot_id)

    pdb_ids: List[str] = []

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ A: æ–°ã—ã„ JSON æ§‹é€ 
    for xref in data.get("uniProtKBCrossReferences", []):
        if xref.get("database") == "PDB" and xref.get("id"):
            pdb_ids.append(xref["id"].upper())

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ B: å¤ã„ JSON æ§‹é€ 
    for xref in data.get("dbReferences", []):
        if xref.get("type") == "PDB" and xref.get("id"):
            pdb_ids.append(xref["id"].upper())

    pdb_ids = sorted(set(pdb_ids))

    if not pdb_ids:
        print("  [DEBUG] UniProt JSON ã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚­ãƒ¼:")
        print("    " + ", ".join(str(k) for k in data.keys()))
        raise RuntimeError(f"UniProt {uniprot_id} ã«å¯¾å¿œã™ã‚‹ PDB ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    return pdb_ids


def fetch_pdb_ids_from_uniprot(uniprot_id_input: str) -> Tuple[str, List[str]]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã® UniProt ID ã‹ã‚‰:
      - Active ãª UniProt ID ã‚’æ±ºå®šã—
      - ãã“ã‹ã‚‰ PDB ID ä¸€è¦§ã‚’å–å¾—ã™ã‚‹

    Returns:
        (resolved_uniprot_id, pdb_ids)
    """
    resolved_id = _resolve_active_uniprot_id(uniprot_id_input)
    pdb_ids = _fetch_pdb_ids_for_active_uniprot(resolved_id)
    return resolved_id, pdb_ids


def download_pdb(pdb_id: str, base_dir: Path) -> Optional[Path]:
    """
    å˜ä¸€ PDB ã‚’ RCSB ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    ã™ã§ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãªã„ã€‚

    RCSB å´ã«å­˜åœ¨ã—ãªã„ï¼ˆ404ï¼‰å ´åˆã¯ None ã‚’è¿”ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
    """
    base_dir.mkdir(parents=True, exist_ok=True)
    pdb_id = pdb_id.upper()
    out_path = base_dir / f"{pdb_id}.pdb"

    if out_path.exists():
        print(f"  âœ“ {pdb_id}.pdb ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        return out_path

    url = RCSB_PDB_DOWNLOAD.format(pdb_id=pdb_id)
    print(f"  â†“ {pdb_id}.pdb ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {url}")

    try:
        resp = requests.get(url, timeout=60)
        if resp.status_code == 404:
            print(f"  âš ï¸ {pdb_id}.pdb ã¯ RCSB ã«å­˜åœ¨ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ (404)")
            return None
        resp.raise_for_status()
    except HTTPError as e:
        # ãã®ä»–ã®HTTPã‚¨ãƒ©ãƒ¼ã¯ã¨ã‚Šã‚ãˆãšãã®ã¾ã¾æŠ•ã’ã‚‹
        raise

    out_path.write_bytes(resp.content)
    return out_path


# ========= æ®‹åŸºæ•°ãƒŸã‚¹ãƒãƒƒãƒé™¤å¤–ã¾ã‚ã‚Š =========


def _extract_coords_with_filtering(
    pdb_paths: List[Path],
) -> Tuple[np.ndarray, list, List[Path], List[Path]]:
    """
    extract_ca_coords_from_files ã‚’ä½¿ã„ã¤ã¤ã€
    ã€Œæ®‹åŸºæ•°ãŒåˆã‚ãªã„ PDB ã‚’è‡ªå‹•ã§é™¤å¤–ã€ã—ãªãŒã‚‰æœ€çµ‚çš„ã«
    ãã‚Œã„ãª coords_all, residues_info ã‚’è¿”ã™ãƒ˜ãƒ«ãƒ‘ãƒ¼ã€‚

    Returns:
        coords_all: np.ndarray (M_total, N, 3)
        residues_info: List[Tuple[res_num, res_name]]
        used_paths: å®Ÿéš›ã«ä½¿ã£ãŸ PDB ãƒ•ã‚¡ã‚¤ãƒ«ã® Path ãƒªã‚¹ãƒˆ
        removed_paths: æ®‹åŸºæ•°ä¸ä¸€è‡´ã§é™¤å¤–ã•ã‚ŒãŸ PDB ãƒ•ã‚¡ã‚¤ãƒ«ã® Path ãƒªã‚¹ãƒˆ
    """
    remaining = list(pdb_paths)
    removed: List[Path] = []

    while True:
        try:
            coords_all, residues_info = extract_ca_coords_from_files([str(p) for p in remaining])
            if removed:
                print(
                    f"\n[Info] éƒ¨åˆ†é…åˆ—ãªã©ã§é™¤å¤–ã•ã‚ŒãŸ PDB: "
                    f"{', '.join(p.name for p in removed)}"
                )
            return coords_all, residues_info, remaining, removed

        except ValueError as e:
            msg = str(e)
            if "Residue count mismatch" not in msg:
                # æƒ³å®šå¤–ã®ã‚¨ãƒ©ãƒ¼ã¯ãã®ã¾ã¾æŠ•ã’ã‚‹
                raise

            bad: Optional[Path] = None
            for p in remaining:
                if str(p) in msg or p.name in msg:
                    bad = p
                    break

            if bad is None:
                # ç‰¹å®šã§ããªã„ãªã‚‰ã‚ãã‚‰ã‚ã¦ä¸Šã«æŠ•ã’ã‚‹
                raise

            print(f"  âš ï¸ {bad.name} ã¯æ®‹åŸºæ•°ãŒç•°ãªã‚‹ãŸã‚é™¤å¤–ã—ã¾ã™: {msg}")
            remaining.remove(bad)
            removed.append(bad)

            if len(remaining) < 2:
                raise RuntimeError(
                    "ãƒ•ãƒ«ãƒ¬ãƒ³ã‚°ã‚¹æ§‹é€ ãŒååˆ†ã«æ®‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€è§£æã‚’ç¶™ç¶šã§ãã¾ã›ã‚“ã€‚"
                )


def _build_residue_data(residues_info) -> List[ResidueData]:
    """
    extract_ca_coords_from_files ãŒè¿”ã™ residues_info ã‹ã‚‰ ResidueData ã®ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

    residues_info ã®æƒ³å®š: List[Tuple[int, str]] = (res_num, res_name)
    """
    residues: List[ResidueData] = []
    for idx, (res_num, res_name) in enumerate(residues_info):
        residues.append(
            ResidueData(
                index=idx,
                residue_number=int(res_num),
                residue_name=str(res_name),
                flex_score=0.0,
                dsa_score=0.0,
            )
        )
    return residues


# ========= å…¬é–‹API: StructureSetã‚’ä½œã‚‹ =========


def build_structure_set_from_uniprot(
    uniprot_id: str,
    max_structures: int = 20,
    base_dir: Path = Path("data"),
) -> StructureSet:
    """
    UniProt ID ã‹ã‚‰:
      - Active UniProt ID è§£æ±º
      - PDB ID å–å¾—
      - PDB ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
      - æ®‹åŸºæ•°ãƒŸã‚¹ãƒãƒƒãƒ & 404 PDB ã‚’é™¤å¤–
      - ResidueData ãƒªã‚¹ãƒˆæ§‹ç¯‰
    ã¾ã§ã‚’è¡Œã„ã€StructureSet ã¨ã—ã¦è¿”ã™ã€‚

    Args:
        uniprot_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã™ã‚‹ UniProt IDï¼ˆInactiveã§ã‚‚OKï¼‰
        max_structures: è§£æã«ä½¿ã†æœ€å¤§PDBæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ20ï¼‰
        base_dir: PDBã‚’ä¿å­˜ã™ã‚‹åŸºæº–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
        StructureSet ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    print("=" * 60)
    print(f"ğŸ” UniProt ID: {uniprot_id} ã®æ§‹é€ ã‚’è‡ªå‹•å–å¾—ã—ã¦æº–å‚™ã—ã¾ã™")
    print("=" * 60)

    # 1) Active ID & PDB ID ä¸€è¦§å–å¾—
    resolved_id, all_pdb_ids = fetch_pdb_ids_from_uniprot(uniprot_id)
    print(f"è¦‹ã¤ã‹ã£ãŸ PDB ID: {len(all_pdb_ids)} å€‹")
    print("  " + ", ".join(all_pdb_ids[:20]) + (" ..." if len(all_pdb_ids) > 20 else ""))

    # 2) max_structures ã‚’é©ç”¨
    if max_structures is not None:
        selected_pdb_ids = all_pdb_ids[:max_structures]
    else:
        selected_pdb_ids = all_pdb_ids

    print(f"\nè§£æå€™è£œ PDB IDï¼ˆæœ€å¤§ {max_structures} å€‹ï¼‰:")
    print("  " + ", ".join(selected_pdb_ids))

    # 3) PDB ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ï¼‰
    #    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã¯ã€Œå…¥åŠ›ã•ã‚ŒãŸ UniProt IDã€ã«ã¶ã‚‰ä¸‹ã’ã‚‹ï¼ˆæ—¢å­˜ä»•æ§˜ã¨åˆã‚ã›ã‚‹ï¼‰
    data_dir = base_dir / uniprot_id
    pdb_paths: List[Path] = []
    for pid in selected_pdb_ids:
        path = download_pdb(pid, data_dir)
        if path is not None:
            pdb_paths.append(path)

    print(f"\nãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ PDB ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(pdb_paths)}")

    if not pdb_paths:
        raise RuntimeError("æœ‰åŠ¹ãª PDB ãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ã‚‚å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€è§£æã‚’ç¶™ç¶šã§ãã¾ã›ã‚“ã€‚")

    # 4) æ®‹åŸºæ•°ãƒŸã‚¹ãƒãƒƒãƒPDBã‚’è‡ªå‹•ã§é™¤å¤–ã—ãªãŒã‚‰ CÎ± åº§æ¨™ã¨æ®‹åŸºæƒ…å ±ã‚’å–å¾—
    coords_all, residues_info, used_paths, removed_paths = _extract_coords_with_filtering(pdb_paths)

    used_pdb_ids = [p.stem.upper() for p in used_paths]
    excluded_pdb_ids = [p.stem.upper() for p in removed_paths]

    print(f"\næœ€çµ‚çš„ã«è§£æã«ä½¿ç”¨ã™ã‚‹ PDB ID ({len(used_pdb_ids)} å€‹):")
    print("  " + ", ".join(used_pdb_ids))

    # 5) ResidueData ã®æ§‹ç¯‰
    residues = _build_residue_data(residues_info)

    # 6) StructureSet ã‚’æ§‹ç¯‰ã—ã¦è¿”ã™
    chain_ids = ["A"] * len(used_pdb_ids)  # ã¨ã‚Šã‚ãˆãšå…¨éƒ¨ A ãƒã‚§ãƒ¼ãƒ³æƒ³å®š

    structure_set = StructureSet(
        uniprot_id_input=uniprot_id,
        uniprot_id_resolved=resolved_id,
        coords=coords_all,
        residues=residues,
        pdb_ids=used_pdb_ids,
        chain_ids=chain_ids,
        source="uniprot_pdb",
        excluded_pdbs=excluded_pdb_ids,
    )

    return structure_set
